{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXSZeV2gTYZQ"
   },
   "source": [
    "# Neural Networks Experiments\n",
    "\n",
    "## Students: <br>\n",
    "Tomás Rojas <br>\n",
    "Matías Montagna <br>\n",
    "Alonso Utreras\n",
    "\n",
    "## The objective of this notebook is to show the results from different models, including different inputs, but trying to get the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import log_info as log\n",
    "from preprocessing import get_consecutive\n",
    "\n",
    "# Get data\n",
    "all_data = pd.read_csv(r\".\\data\\cleaned-data\\temuco_cleaned_data.csv\")\n",
    "\n",
    "all_data = all_data.dropna()\n",
    "\n",
    "all_data[\"mp_25\"] = all_data[\"mp_2,5\"]\n",
    "all_data = all_data.drop([\"mp_2,5\"], axis=1)\n",
    "\n",
    "\n",
    "X = all_data[all_data.columns[2:-1]]\n",
    "Y = all_data[all_data.columns[-1]]\n",
    "# Y = all_data[all_data.columns[:-4]].join(Y) # para que tenga todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into train, test and validation sets\n",
    "We chose a train size of 70% of all data, while 15% corresponds to test and 15% to validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = int(len(all_data) * 0.7)\n",
    "\n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]\n",
    "\n",
    "_X_train, _X_test, _y_train, _y_val = train_test_split(X, Y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting device to work with. Use cuda if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = ('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes for training our models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model, which is a simple ff NN using just date.\n",
    "Simple feedforward NN\n",
    "Input: Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM layer + linear to get output\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, n_hidden=128, n_layers=3,  output_size=1, model_name=\"LSTM\", batch_size=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=n_hidden,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=n_hidden, out_features=output_size)\n",
    "        self.name = model_name\n",
    "        # error with double type\n",
    "\n",
    "        #h_0 of shape (num_layers * num_directions, batch, hidden_size)\n",
    "        #c_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        \"\"\"Initialize hidden state\"\"\"\n",
    "        self.hidden = (\n",
    "            torch.zeros(self.n_layers, self.batch_size, self.n_hidden).to(device),\n",
    "            torch.zeros(self.n_layers, self.batch_size, self.n_hidden).to(device)\n",
    "            )\n",
    "\n",
    "    def forward(self, _input):\n",
    "\n",
    "        if len(_input.size()) == 3:\n",
    "            seq_len = _input.size()[1]\n",
    "\n",
    "        if len(_input.size()) == 2:\n",
    "            seq_len = _input.size()[0]\n",
    "\n",
    "        _input = _input.view(seq_len, self.batch_size , self.input_size).float()\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(_input, self.hidden)\n",
    "        lstm_out = lstm_out.float()\n",
    "\n",
    "        y_pred = self.linear(lstm_out.view(seq_len, -1)).float()\n",
    "  \n",
    "        return y_pred\n",
    "\n",
    "# Setting model to use and its name\n",
    "model_name = \"Temp PM LSTM 3 layers. 128 hidden size\"\n",
    "model_1_temp_pm = LSTMModel(6, 128, 3, 1, \"Temp PM LSTM 3 layers. 128 hidden size\")\n",
    "loss_1 = nn.MSELoss()\n",
    "\n",
    "# Setting model, loss and optimizer\n",
    "model = model_1_temp_pm.to(device)\n",
    "loss = loss_1.to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Setting logger\n",
    "Logger = log.LogInfo(\n",
    "    model=model, \n",
    "    logging_name=model_name\n",
    "    )\n",
    "Logger.add_info(\"Model using LSTM. hidden dim = 128.\\n Having 3 layers.\\n Data normalized\")\n",
    "\n",
    "# Hyperparamters\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def init_weights(model):\n",
    "    # Inicializamos los pesos como aleatorios\n",
    "    for name, param in model.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# TODO: Completar\n",
    "def batcher(training_data, batch_size=365*24):\n",
    "    \"\"\"TODO: FIX for our data. We still don't know  how our data is going to be.  \"\"\"\n",
    "    inout_seq = []\n",
    "    L = len(training_data)\n",
    "    for i in range(L-batch_size):\n",
    "        train_seq = input_data[i:i+batch_size]\n",
    "        train_label = input_data[i+batch_size:i+batch_size+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "\n",
    "def train(model, x_train, y_train, optimizer, loss_function, epochs=5, batch_size=365*24):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # each epoch\n",
    "        epoch_loss = 0\n",
    "        best_test_loss = float('inf')\n",
    "        # _input.size()[1], 1 , self.input_size)\n",
    "        # x_i => (1 , self.input_size)\n",
    "        # x_i.size[1]\n",
    "        for x_i, y_i in zip(x_train, y_train):\n",
    "\n",
    "\n",
    "            # Each batch\n",
    "            # initialize the hidden state.\n",
    "            model.reset_hidden_state()\n",
    "\n",
    "            x_i = x_i.to(device)\n",
    "            y_i = y_i.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_i).float()\n",
    "\n",
    "            loss = loss_function(y_pred, y_i).float()\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Save results from the best trained model\n",
    "        if epoch_loss < best_test_loss:\n",
    "            best_test_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), '{}.pt'.format(model.name))\n",
    "            \n",
    "        total_loss += epoch_loss\n",
    "        print(f'epoch: {i} loss: {epoch_loss:10.8f}')\n",
    "\n",
    "    print(f'Average loss: {total_loss/len(x_train):4f}')\n",
    "    return total_loss\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def test(model, x_test, y_test, loss_function, batch_size=365*24):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_i, y_i in zip(x_test, y_test):\n",
    "            # predict data using the given model\n",
    "            model.reset_hidden_state()\n",
    "\n",
    "            prediction = model(x_i)\n",
    "            # Compute loss\n",
    "            total_loss += loss_function(prediction, y_i).item()\n",
    "\n",
    "    print(total_loss)\n",
    "    return total_loss\n",
    "\n",
    "def load_best_model(model):\n",
    "    return model.load_state_dict(torch.load(f'{model.name}.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training\n",
    "def execute_training(model, x_train, y_train, x_test, y_test, optimizer, loss_function, logger, n_epochs=5, batch_size=365*24):\n",
    "    # Train\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, x_train, y_train, optimizer, loss_function, n_epochs, batch_size)\n",
    "    end_time = time.time();\n",
    "    train_time = end_time - start_time\n",
    "\n",
    "    print(f'Training time = {train_time}')\n",
    "    print(f'Train Loss: {train_loss}')\n",
    "\n",
    "\n",
    "    # Test\n",
    "    start_time = time.time()\n",
    "\n",
    "    test_loss = test(model, x_test, y_test, loss_function, batch_size)\n",
    "    end_time = time.time()\n",
    "    test_time = end_time - start_time \n",
    "\n",
    "    print(f'\\t Val. Loss: {test_loss:.3f}')\n",
    "\n",
    "    logger.model_loss['train'] = train_loss\n",
    "    logger.model_loss['test'] = test_loss\n",
    "    logger.set_train_test_size(x_train, x_test)\n",
    "    logger.set_training_time(train_time)\n",
    "    # logger.set_epochs(n_epochs)\n",
    "    # logger.set_optimizer(optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean CUDA RAM\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing train data:\n",
    "We read here https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/\n",
    "that it is important to normalize data when working with time series. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(np.asarray(X[0:5]))\n",
    "\n",
    "for i in range(5, 100, 5):\n",
    "    array = np.asarray(X[i:i+5])\n",
    "    tensor = torch.cat((tensor, torch.from_numpy(array)), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.asarray(_X_train.values)\n",
    "y_train_np = np.asarray(_y_train.values)\n",
    "\n",
    "x_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_train_np = np.asarray(_X_train.values)\n",
    "y_train_np = np.asarray(_y_train.values)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_normalized = scaler.fit_transform(x_train_np)\n",
    "y_train_normalized = scaler.fit_transform(y_train_np.reshape(-1, 1))\n",
    "\n",
    "X_train = torch.from_numpy(X_train_normalized)\n",
    "y_train = torch.from_numpy(y_train_normalized)\n",
    "\n",
    "# Transforming data into tensors\n",
    "# train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming data Shape to work well with batches and our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = X_train.view(1, X_train.size()[0],  X_train.size()[1])\n",
    "y_tensor = y_train.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tensor[:,0:1000,:].to(device)\n",
    "y_train = y_tensor[:,0:1000].to(device)\n",
    "X_test = X_tensor[:,1000:1100, :].to(device)\n",
    "y_test = y_tensor[:,1000:1100].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'The current model contains {count_parameters(model)} trainable parameters.')     \n",
    "model = model.float()\n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "execute_training(\n",
    "    model=model,\n",
    "    x_train=X_train,\n",
    "    y_train=y_train,\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss,\n",
    "    logger=Logger,\n",
    "    n_epochs=n_epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_best_model(model)\n",
    "\n",
    "# Export info to a logger to store results\n",
    "Logger.export_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting predicted data vs real data using testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model(X_train)\n",
    "\n",
    "X_train_np = X_train.cpu().detach().numpy()\n",
    "y_train_np = y_train.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "y_pred_plot = y_pred.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "actual_values = \\\n",
    "    scaler.inverse_transform(y_train_np.reshape(-1, 1))\n",
    "\n",
    "actual_predictions = \\\n",
    "    scaler.inverse_transform(np.array(y_pred_plot).reshape(-1, 1))\n",
    "\n",
    "# actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(actual_values, marker=\"*\", label=\"results\")\n",
    "plt.plot(actual_predictions, marker=\"+\", label=\"predictions\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Transform tensors to numpy arrays\n",
    "y_pred = model(X_test)\n",
    "X_test_np = X_test.cpu().detach().numpy()\n",
    "y_test_np = y_test.cpu().detach().numpy()\n",
    "y_pred_np = y_pred.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot both real values and prediction values\n",
    "results_plot = plt.scatter(X_test_np, y_test_np, marker=\"*\", label=\"results\")\n",
    "pred_plot = plt.scatter(X_test_np, y_pred_np, marker=\"+\", label=\"predictions\")\n",
    "\n",
    "ax.legend()            \n",
    "plt.xlabel(\"temperature\")\n",
    "plt.ylabel(\"mp2.5\")\n",
    "plt.title(model.name)\n",
    "\n",
    "# plot results and store it in results directory\n",
    "plt.show()\n",
    "plt.savefig(f'./results/{model.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Proyecto_de_ML_prediccion_PM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda768978131ac44bf49e7b16a08459a01b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}