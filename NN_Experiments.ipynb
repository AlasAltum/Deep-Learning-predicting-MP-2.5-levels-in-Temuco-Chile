{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXSZeV2gTYZQ"
   },
   "source": [
    "# Neural Networks Experiments\n",
    "\n",
    "## Estudiantes: <br>\n",
    "Tomás Rojas <br>\n",
    "Matías Montagna <br>\n",
    "Alonso Utreras\n",
    "\n",
    "## The objective of this notebook is to show the results from different models, including different inputs, but trying to get the same output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "all_data = pd.DataFrame(path=\"./data/product1.csv\")\n",
    "X = all_data[0:-1]\n",
    "y = all_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing data into train, test and validation sets\n",
    "We chose a train size of 70% of all data, while 15% corresponds to test and 15% to validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "test_data_size = int(len(whole_data) * 0.7)\n",
    "\n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]\n",
    "\n",
    "# We can do this if sklearn works fine with DataFrames\n",
    "X_train, X_2, y_train, y_2 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_2, y_2, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing train data:\n",
    "We read here https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/\n",
    "that it is important to normalize data when working with time series. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))\n",
    "\n",
    "# Transforming data into tensors\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes for training our models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model, which is a simple ff NN using just date.\n",
    "Simple feedforward NN\n",
    "Input: Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# TODO: Completar\n",
    "def batcher(training_data, batch_size=365*24):\n",
    "    \"\"\"This generates our batches. Given the  \"\"\"\n",
    "    inout_seq = []\n",
    "    L = len(training_data)\n",
    "    for i in range(L-batch_size):\n",
    "        # train_seq = input_data[i:i+batch_size]\n",
    "        # train_label = input_data[i+batch_size:i+batch_size+1]\n",
    "        # inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "\n",
    "def train(model, training_data, optimizer, loss_function, epochs=5, batch_size=365*24):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "         for seq, labels in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "            y_pred = model(seq)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'epoch: {i} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def test(model, test_data, batch_size=365*24):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_data:\n",
    "            # predict data using the given model\n",
    "            predictions = model(text)\n",
    "            # Compute loss\n",
    "            total_loss += criterion(predictions, labels).item()\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    end_time = time.time();\n",
    "    train_time = end_time - start_time\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "\n",
    "    # Test\n",
    "    start_time = time.time()\n",
    "    valid_loss = evaluate(model, , criterion)\n",
    "    end_time = time.time()\n",
    "    test_time = end_time - start_time \n",
    "\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    # Save results from the best trained model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "    # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with best results in the validation dataset\n",
    "model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "\n",
    "# Limpiar ram de cuda\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Plot predictions v/s real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Proyecto_de_ML_prediccion_PM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}